# Running AlphaFold on the Artemis HPC

## AlphaFold on Artemis

AlphaFold can be accessed by executing
```bash
module load alphafold
```

There are several (large) genetic databases and parameters AlphaFold requires. Different versions of these are conveniently available on Artemis in the common folder: `/project/data/alphafold2/`
If there is additional databases you require, please fill in a [support ticket](https://sydneyuni.service-now.com/sm?id=sc_cat_item&sys_id=1ab0bb626d2935008dd31a4dcf150a21&sysparm_category=56db92a0db1f73042d38cae43a961918).

To actually run a computationally intensive AlphaFold job, we must create a PBS *jobscript*, which is a standard shell script with a few PBS-specific directives, that is sent to the job scheduler for execution.

### Make a PBS Jobscript

Make a new file called `alpha_job.pbs`.
Execute `nano alpha_job.pbs` to edit a new text file in the `nano` text-editor. Make the changes then hit `cntrl+x` to exit the `nano` text-editor, save the changes as prompted.

The contents at a minimum, should look something like this.

```bash
#!/bin/bash

#PBS -P Training
#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1
#PBS -l walltime=04:00:00
#PBS -N job01_gpu

# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)
module load alphafold/2.2.0-gpu hmmer hh-suite kalign

# Navigate to your directory
cd $PBS_O_WORKDIR

# Set a working directory
export WORKDIR=`pwd`

# Set the alphafold base database directory
export ALPHADB=/project/data/alphafold2/20220323

# Run the AlphaFold2 prediction command. Note most database paths are required
run_alphafold.py \
        --data_dir=${ALPHADB} \
        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \
        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \
        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \
        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \
        --fasta_paths=/project/Training/DATA/input.fasta \
        --output_dir=${WORKDIR}/output_directory_gpu \
        --db_preset=full_dbs \
        --max_template_date=2022-03-23 \
        --use_gpu_relax=False \
        --model_preset=monomer \
        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \
        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \
        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08
```

### Submit a PBS Jobscript to the queue

Now we can submit the job to the scheduler
```bash
qsub alpha_job.pbs
```

This will execute when compute resources become available. Check the status with:

```bash
qstat -x -u <unikey>
```

You will see most requirements are on Artemis already, but you must bring your own `.fasta` file.
